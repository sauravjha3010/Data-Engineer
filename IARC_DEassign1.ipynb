{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas pyarrow matplotlib seaborn kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfj6_PeXiqxL",
        "outputId": "7f9e297a-c743-4d18-ffd7-24648509faa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (14.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.7.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "# Load data\n",
        "movies_df = pd.read_csv('/content/movies_metadata.csv', low_memory=False)\n",
        "ratings_df = pd.read_csv('/content/ratings_small.csv')\n",
        "\n",
        "# Create 'tables' (DataFrames) for our data warehouse\n",
        "def create_movie_dimension(df):\n",
        "    movie_dim = df[['id', 'title', 'release_date', 'budget', 'revenue', 'runtime']]\n",
        "    movie_dim['release_date'] = pd.to_datetime(movie_dim['release_date'], errors='coerce')\n",
        "    return movie_dim\n",
        "\n",
        "def create_genre_dimension(df):\n",
        "    genres = df['genres'].apply(eval).explode()\n",
        "    return pd.json_normalize(genres)[['id', 'name']]\n",
        "\n",
        "def create_fact_table(movies_df, ratings_df):\n",
        "    movies_df['id'] = pd.to_numeric(movies_df['id'], errors='coerce')\n",
        "    return pd.merge(ratings_df, movies_df[['id', 'title']], left_on='movieId', right_on='id', how='inner')\n",
        "\n",
        "movie_dim = create_movie_dimension(movies_df)\n",
        "genre_dim = create_genre_dimension(movies_df)\n",
        "fact_table = create_fact_table(movies_df, ratings_df)\n",
        "\n",
        "print(\"Data Warehouse tables created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1D_6_WrirlB",
        "outputId": "fa208c2d-d96b-4857-ab1d-a756a509f91c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-567e0c15c1cd>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  movie_dim['release_date'] = pd.to_datetime(movie_dim['release_date'], errors='coerce')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Warehouse tables created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "def extract():\n",
        "    movies_df = pd.read_csv('/content/movies_metadata.csv', low_memory=False)\n",
        "    ratings_df = pd.read_csv('/content/ratings_small.csv')\n",
        "    return movies_df, ratings_df\n",
        "\n",
        "def transform(movies_df, ratings_df):\n",
        "    movie_dim = create_movie_dimension(movies_df)\n",
        "    genre_dim = create_genre_dimension(movies_df)\n",
        "    fact_table = create_fact_table(movies_df, ratings_df)\n",
        "    return movie_dim, genre_dim, fact_table\n",
        "\n",
        "def load(movie_dim, genre_dim, fact_table):\n",
        "    movie_dim.to_parquet('movie_dimension.parquet')\n",
        "    genre_dim.to_parquet('genre_dimension.parquet')\n",
        "    fact_table.to_parquet('ratings_fact.parquet')\n",
        "\n",
        "def etl_pipeline():\n",
        "    print(\"Extracting data...\")\n",
        "    movies_df, ratings_df = extract()\n",
        "\n",
        "    print(\"Transforming data...\")\n",
        "    movie_dim, genre_dim, fact_table = transform(movies_df, ratings_df)\n",
        "\n",
        "    print(\"Loading data...\")\n",
        "    load(movie_dim, genre_dim, fact_table)\n",
        "\n",
        "    print(\"ETL pipeline completed.\")\n",
        "\n",
        "# Run the ETL pipeline\n",
        "etl_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3AXWa0_i1UX",
        "outputId": "53fdc0bd-8e0a-401c-ec97-813cab577b8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data...\n",
            "Transforming data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-567e0c15c1cd>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  movie_dim['release_date'] = pd.to_datetime(movie_dim['release_date'], errors='coerce')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "ETL pipeline completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def partition_by_year(df, date_column):\n",
        "    df['year'] = df[date_column].dt.year\n",
        "    for year, group in df.dropna(subset=['year']).groupby('year'):\n",
        "        pq.write_table(pa.Table.from_pandas(group), f'movies_{int(year)}.parquet')\n",
        "\n",
        "def create_index(df, column):\n",
        "    return df.set_index(column).sort_index()\n",
        "\n",
        "# Usage\n",
        "partition_by_year(movie_dim, 'release_date')\n",
        "movie_dim_indexed = create_index(movie_dim, 'id')\n",
        "\n",
        "print(\"Optimization complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owhbHVJmkaym",
        "outputId": "54b5ff4a-8914-4303-9fb3-86b52219a1e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a3c90a247970>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['year'] = df[date_column].dt.year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "\n",
        "def data_lineage(df, source):\n",
        "    df['DataSource'] = source\n",
        "    df['LoadTimestamp'] = datetime.datetime.now()\n",
        "    return df\n",
        "\n",
        "def audit_log(operation, user):\n",
        "    with open('audit_log.txt', 'a') as f:\n",
        "        f.write(f\"{datetime.datetime.now()} - {operation} performed by {user}\\n\")\n",
        "\n",
        "def access_control(user, allowed_users):\n",
        "    if user in allowed_users:\n",
        "        return True\n",
        "    else:\n",
        "        raise PermissionError(\"User not authorized\")\n",
        "\n",
        "# Usage\n",
        "movie_dim = data_lineage(movie_dim, \"/content/movies_metadata.csv\")\n",
        "audit_log(\"ETL Process\", \"DataEngineer1\")\n",
        "try:\n",
        "    if access_control(\"DataEngineer1\", [\"DataEngineer1\", \"DataAnalyst1\"]):\n",
        "        print(\"Access granted\")\n",
        "except PermissionError as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DRS6iU2keA5",
        "outputId": "b2b016b4-03a9-43c9-f54d-ae6c9b907c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access granted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-88d48fe1ed19>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['DataSource'] = source\n",
            "<ipython-input-6-88d48fe1ed19>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['LoadTimestamp'] = datetime.datetime.now()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from airflow import DAG\n",
        "from airflow.operators.python_operator import PythonOperator\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "default_args = {\n",
        "    'owner': 'airflow',\n",
        "    'depends_on_past': False,\n",
        "    'start_date': datetime(2023, 1, 1),\n",
        "    'email_on_failure': False,\n",
        "    'email_on_retry': False,\n",
        "    'retries': 1,\n",
        "    'retry_delay': timedelta(minutes=5),\n",
        "}\n",
        "\n",
        "dag = DAG(\n",
        "    'movie_etl',\n",
        "    default_args=default_args,\n",
        "    description='ETL process for movie data warehouse',\n",
        "    schedule_interval=timedelta(days=1),\n",
        ")\n",
        "\n",
        "extract_task = PythonOperator(\n",
        "    task_id='extract',\n",
        "    python_callable=extract,\n",
        "    dag=dag,\n",
        ")\n",
        "\n",
        "transform_task = PythonOperator(\n",
        "    task_id='transform',\n",
        "    python_callable=transform,\n",
        "    dag=dag,\n",
        ")\n",
        "\n",
        "load_task = PythonOperator(\n",
        "    task_id='load',\n",
        "    python_callable=load,\n",
        "    dag=dag,\n",
        ")\n",
        "\n",
        "extract_task >> transform_task >> load_task\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "KKcaCdsVkotc",
        "outputId": "b63626b2-7f91-40c8-acf1-2047f40180fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'airflow'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-2772219fc7f3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mairflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDAG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mairflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_operator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPythonOperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m default_args = {\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'airflow'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}